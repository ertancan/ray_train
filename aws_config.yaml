cluster_name: verita-security-llama-2-7b

# The maximum number of worker nodes to launch in addition to the head
# node.
max_workers: 17

docker:
  image: "rayproject/ray-ml:latest-gpu" # You can change this to latest-cpu if you don't need GPU support and want a faster startup
    # image: rayproject/ray:latest-gpu   # use this one if you don't need ML dependencies, it's faster to pull
  container_name: "ray_container"
  # If true, pulls latest version of image. Otherwise, `docker run` will only pull the image
  # if no cached version is present.
  pull_before_run: True
  run_options:  # Extra options to pass into "docker run"
    - --ulimit nofile=65536:65536

provider:
    type: aws
    region: eu-central-1

auth:
  ssh_user: ubuntu


available_node_types:
    ray_head_default:
        min_workers: 1
        max_workers: 1
        # The resources provided by this node type.
        resources: {"CPU": 4}
        node_config:
            InstanceType: m5.xlarge
           
    ray_worker_small:
        # The minimum number of worker nodes of this type to launch.
        # This number should be >= 0.
        min_workers: 16
        # The maximum number of worker nodes of this type to launch.
        # This takes precedence over min_workers.
        max_workers: 16
        # The resources provided by this node type.
        resources: {"CPU": 16}
        # Provider-specific config for the head node, e.g. instance type. By default
        # Ray will auto-configure unspecified fields such as subnets and ssh-keys.
        # For more documentation on available fields, see:
        # https://cloud.google.com/compute/docs/reference/rest/v1/instances/insert
        node_config:
            InstanceType: g5.4xlarge
head_node_type: ray_head_default

head_setup_commands:
    - sudo mkdir /mnt/local_storage || true
    - sudo chmod 777 /mnt/local_storage
    - sudo apt-get update
    - sudo apt-get install awscli -y --fix-missing
    - pip install pip install ray==2.7.0rc0
    - rm -rf ray_train
    - git clone https://github.com/ertancan/ray_train.git
    - aws s3 cp s3://forensic-training-data/ray/ ray_train/training_data --recursive
    - cd ray_train && chmod +x ./run_llama_ft.sh && ./run_llama_ft.sh --size=7b

worker_setup_commands:
    - pip install pip install ray==2.7.0rc0
    - sudo mkdir /mnt/local_storage || true
    - sudo chmod 777 /mnt/local_storage


# Command to start ray on the head node. You don't need to change this.
head_start_ray_commands:
    - ray stop
    - >-
      ray start
      --head
      --port=6379
      --object-manager-port=8076
      --autoscaling-config=~/ray_bootstrap_config.yaml

# Command to start ray on worker nodes. You don't need to change this.
worker_start_ray_commands:
    - ray stop
    - >-
      ray start
      --address=$RAY_HEAD_IP:6379
      --object-manager-port=8076